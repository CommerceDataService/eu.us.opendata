term_test <- c()
if(length(splits == 1)){
} else if(length(splits)==2){
term_test <- rec
} else if(length(splits)>2){
for(k in 3:length(splits)){
print(term_test)
term_test <- c(term_test, paste(splits[k-2],splits[k-1], splits[k]))
if(k >3){
term_test <- c(term_test, paste(splits[k-3],splits[k-2],splits[k-1], splits[k]))
}
}
}
rec <-  "the gross domestic product gross national product"
splits <-  unlist(strsplit(rec," "))
term_test <- c()
if(length(splits == 1)){
} else if(length(splits)==2){
term_test <- rec
} else if(length(splits)>2){
for(k in 3:length(splits)){
print(term_test)
term_test <- c(term_test, paste(splits[k-2],splits[k-1], splits[k]))
if(k >3){
term_test <- c(term_test, paste(splits[k-3],splits[k-2],splits[k-1], splits[k]))
}
}
}
splits <-  unlist(strsplit(rec," "))
splits
term_test <- c()
length(splits == 1)
if(length(splits == 1)){
} else if(length(splits)==2){
term_test <- rec
} else if(length(splits)>2){
for(k in 3:length(splits)){
print(term_test)
term_test <- c(term_test, paste(splits[k-2],splits[k-1], splits[k]))
if(k >3){
term_test <- c(term_test, paste(splits[k-3],splits[k-2],splits[k-1], splits[k]))
}
}
}
k
for(k in 3:length(splits)){
term_test <- c(term_test, paste(splits[k-2],splits[k-1], splits[k]))
if(k >3){
term_test <- c(term_test, paste(splits[k-3],splits[k-2],splits[k-1], splits[k]))
}
}
length(splits)>2
parse_query <- function(rec){
splits <-  unlist(strsplit(rec," "))
term_test <- c()
if(length(splits == 1)){
} else if(length(splits)==2){
term_test <- rec
} else if(length(splits)>2){
for(k in 3:length(splits)){
print(k)
term_test <- c(term_test, paste(splits[k-2],splits[k-1], splits[k]))
if(k >3){
term_test <- c(term_test, paste(splits[k-3],splits[k-2],splits[k-1], splits[k]))
}
}
}
return(term_test)
}
parse_query("ha ha")
rm(k)
parse_query <- function(rec){
splits <-  unlist(strsplit(rec," "))
term_test <- c()
if(length(splits == 1)){
} else if(length(splits)==2){
term_test <- rec
} else if(length(splits)>2){
for(k in 3:length(splits)){
print(k)
term_test <- c(term_test, paste(splits[k-2],splits[k-1], splits[k]))
if(k >3){
term_test <- c(term_test, paste(splits[k-3],splits[k-2],splits[k-1], splits[k]))
}
}
}
return(term_test)
}
parse_query("ha ha")
parse_query <- function(rec){
splits <-  unlist(strsplit(rec," "))
term_test <- c()
if(length(splits)== 1){
} else if(length(splits)==2){
term_test <- rec
} else if(length(splits)>2){
for(k in 3:length(splits)){
print(k)
term_test <- c(term_test, paste(splits[k-2],splits[k-1], splits[k]))
if(k >3){
term_test <- c(term_test, paste(splits[k-3],splits[k-2],splits[k-1], splits[k]))
}
}
}
return(term_test)
}
parse_query("ha ha")
rec <-  "the gross domestic product gross national product"
##Parse terms into 2 to 4 n-grams
parse_query <- function(rec){
splits <-  unlist(strsplit(rec," "))
term_test <- c()
if(length(splits)== 1){
} else if(length(splits)==2){
term_test <- rec
} else if(length(splits)>2){
for(k in 3:length(splits)){
term_test <- c(term_test, paste(splits[k-2],splits[k-1], splits[k]))
if(k >3){
term_test <- c(term_test, paste(splits[k-3],splits[k-2],splits[k-1], splits[k]))
}
}
}
return(term_test)
}
parse_query(rec)
combos <- parse_query(rec)
combos
##Run all n-grams to match
matches <- data.frame()
for(k in combos){
a <- master[agrep(k, master[,2] ),ignore.case=TRUE]
if(nrow(a)>0){
print("yes")
a$ngram <- k
matches <- rbind(matches, a)
}
}
for(k in combos){
a <- master[agrep(k, master[,2],ignore.case=TRUE ),]
if(nrow(a)>0){
print("yes")
a$ngram <- k
matches <- rbind(matches, a)
}
}
matches
matches <- data.frame()
nrow(matches)
gsub(matches$ngram, matches$acronym,rec)
matches <- data.frame()
for(k in combos){
a <- master[agrep(k, master[,2],ignore.case=TRUE ),]
if(nrow(a)>0){
print("yes")
a$ngram <- k
matches <- rbind(matches, a)
}
}
if(nrow(matches)>0){
gsub(matches$ngram, matches$acronym,rec)
}
if(nrow(matches)>0){
for(k in 1:nrow(matches)){
rec <- gsub(matches$ngram[k], matches$acronym[k],rec)
}
}
rec
rec <-  "the gross domestic product gross nationa product"
##Parse terms into 2 to 4 n-grams
parse_query <- function(rec){
splits <-  unlist(strsplit(rec," "))
term_test <- c()
if(length(splits)== 1){
} else if(length(splits)==2){
term_test <- rec
} else if(length(splits)>2){
for(k in 3:length(splits)){
term_test <- c(term_test, paste(splits[k-2],splits[k-1], splits[k]))
if(k >3){
term_test <- c(term_test, paste(splits[k-3],splits[k-2],splits[k-1], splits[k]))
}
}
}
return(term_test)
}
combos <- parse_query(rec)
##Run all n-grams to match
matches <- data.frame()
for(k in combos){
a <- master[agrep(k, master[,2],ignore.case=TRUE ),]
if(nrow(a)>0){
print("yes")
a$ngram <- k
matches <- rbind(matches, a)
}
}
if(nrow(matches)>0){
for(k in 1:nrow(matches)){
rec <- gsub(matches$ngram[k], matches$acronym[k],rec)
}
}
rec
consistent_query <- function(rec){
##Parse query
combos <- parse_query(rec)
##Run all n-grams to match
matches <- data.frame()
for(k in combos){
a <- master[agrep(k, master[,2],ignore.case=TRUE ),]
if(nrow(a)>0){
print("yes")
a$ngram <- k
matches <- rbind(matches, a)
}
}
##Replace parts of query
if(nrow(matches)>0){
for(k in 1:nrow(matches)){
rec <- gsub(matches$ngram[k], matches$acronym[k],rec)
}
}
return(rec)
}
consistent_query("the gross domestic product")
consistent_query("the gross")
consistent_query("the gross domestic")
consistent_query("gross domestic")
rec <-  "the gross domestic product gross national product"
##Parse terms into 2 to 4 n-grams
parse_query <- function(rec){
splits <-  unlist(strsplit(rec," "))
term_test <- c()
if(length(splits)== 1){
} else if(length(splits)==2){
term_test <- rec
} else if(length(splits)>2){
for(k in 3:length(splits)){
term_test <- c(term_test, paste(splits[k-2],splits[k-1], splits[k]))
if(k >3){
term_test <- c(term_test, paste(splits[k-3],splits[k-2],splits[k-1], splits[k]))
}
}
}
return(term_test)
}
consistent_query <- function(rec){
##Parse query
combos <- parse_query(rec)
##Run all n-grams to match
matches <- data.frame()
for(k in combos){
a <- master[agrep(k, master[,2],ignore.case=TRUE ),]
if(nrow(a)>0){
a$ngram <- k
matches <- rbind(matches, a)
}
}
##Replace parts of query
if(nrow(matches)>0){
for(k in 1:nrow(matches)){
rec <- gsub(matches$ngram[k], matches$acronym[k],rec)
}
}
return(rec)
}
consistent_query("gross domestic")
consistent_query("gross nat")
consistent_query("GNI")
consistent_query("poverty")
consistent_query("personal inc")
consistent_query("personal income")
consistent_query("personal consum")
consistent_query("personal consumption")
consistent_query("personal consumption expenditure")
View(master)
consistent_query("supplemental nutri")
consistent_query("supp nutri")
consistent_query("quarter census")
install.packages(hunspell)
install.packages("hunspell")
words <- c("beer", "wiskey", "wine")
hunspell_check(words)
library(hunspell)
words <- c("beer", "wiskey", "wine")
hunspell_check(words)
bad_words <- hunspell_find("spell checkers are not neccessairy for langauge ninja's")
hunspell_suggest(bad_words[[1]])
bad_words <- hunspell_find("supplem incomee")
hunspell_suggest(bad_words[[1]])
bad_words <- hunspell_find("supplemen incomee")
hunspell_suggest(bad_words[[1]])
bad_words <- hunspell_find("supplemen incom")
hunspell_suggest(bad_words[[1]])
Supplementalhunspell_find("supplemen incom") security income
hunspell_find("supplemen incom")
for(k in 1:nrow(master)){
print(hunspell_find(master[k,2]))
}
rec
splits <-  unlist(strsplit(rec," "))
splits
hunspell_find(k)
for(k in splits){
}
k
checked <- hunspell_find(k)
hunspell_find(k)
hunspell_find("checked")
hunspell_find("asd")
checked <- hunspell_find(k)
class(checked)
length(checked)
length(checked[1])
hunspell_find("asd")
length(hunspell_find("asd"))
unlist(hunspell_find("asd"))
unlist(hunspell_find("product"))
length(unlist(hunspell_find("product")))
length(unlist(hunspell_find("asd")))
hunspell_suggest(k)
spell=TRUE
if(spell){
for(k in 1:length(splits)){
if(length(unlist(hunspell_find(splits[k])))>0){
splits[k] <- hunspell_suggest(k)[1]
}
}
}
splits
rec <-  "the stix gros domestik product gross national product"
splits <-  unlist(strsplit(rec," "))
##Spell check
if(spell){
for(k in 1:length(splits)){
if(length(unlist(hunspell_find(splits[k])))>0){
splits[k] <- hunspell_suggest(k)[1]
}
}
}
splits <-  unlist(strsplit(rec," "))
##Spell check
if(spell == TRUE){
for(k in 1:length(splits)){
if(length(unlist(hunspell_find(splits[k])))>0){
splits[k] <- hunspell_suggest(k)[1]
}
}
}
spellCheck = TRUE
##Spell check
if(spellCheck == TRUE){
for(k in 1:length(splits)){
if(length(unlist(hunspell_find(splits[k])))>0){
splits[k] <- hunspell_suggest(k)[1]
}
}
}
print("check")
##Spell check
if(spellCheck == TRUE){
print("check")
for(k in 1:length(splits)){
if(length(unlist(hunspell_find(splits[k])))>0){
splits[k] <- hunspell_suggest(k)[1]
}
}
}
##Spell check
if(spellCheck == TRUE){
print("check")
for(k in 1:length(splits)){
print("check")
if(length(unlist(hunspell_find(splits[k])))>0){
splits[k] <- hunspell_suggest(k)[1]
}
}
}
splits[k]
hunspell_find(splits[k]))
hunspell_find(splits[k])
length(unlist(hunspell_find(splits[k])))>0
hunspell_suggest(k)[1]
hunspell_suggest(k)
splits[k] <- hunspell_suggest(splits[k])[1]
splits <-  unlist(strsplit(rec," "))
##Spell check
if(spellCheck == TRUE){
print("check")
for(k in 1:length(splits)){
print("check")
if(length(unlist(hunspell_find(splits[k])))>0){
splits[k] <- hunspell_suggest(splits[k])[1]
}
}
}
splhunspell_suggest(splits[k])
hunspell_suggest(splits[k])
splits[k]
hunspell_suggest(splits[k])
hunspell_suggests("gross")
hunspell_suggest("gross")
hunspell_suggest("gros")
hunspell_suggest("gross")
class(split)
splits <-  unlist(strsplit(rec," "))
##Spell check
if(spellCheck == TRUE){
print("check")
for(k in 1:length(splits)){
print("check")
if(length(unlist(hunspell_find(splits[k])))>0){
splits[k] <- unlist(hunspell_suggest(splits[k]))[1]
}
}
}
splits
rec
hunspell_suggest("domestik")
#' Load local acronym metadata cache
#'
#' @keywords internal
#' @return Local cache of acronyms
#' @import data.table
#' @export
loadLocalAcronym <- function(){
localPath <- paste0(.libPaths()[1], '/eu.us.opendata/rawdata')
tryCatch({
localAcronyms <- read.csv(paste0(localPath, '/Acronym_Table.csv'));
return(localAcronyms);
})
}
loadLocalAcronym()
searchParse <- function(rec, spellCheck = TRUE){
requireNamespace('hunspell', quietly = TRUE)
splits <-  unlist(strsplit(rec," "))
##Spell check using hunspell
if(spellCheck == TRUE){
print("check")
for(k in 1:length(splits)){
print("check")
if(length(unlist(hunspell_find(splits[k])))>0){
splits[k] <- unlist(hunspell_suggest(splits[k]))[1]
}
}
}
##2 to 4 n-grams
term_test <- c()
if(length(splits)== 1){
} else if(length(splits)==2){
term_test <- rec
} else if(length(splits)>2){
for(k in 3:length(splits)){
term_test <- c(term_test, paste(splits[k-2],splits[k-1], splits[k]))
if(k >3){
term_test <- c(term_test, paste(splits[k-3],splits[k-2],splits[k-1], splits[k]))
}
}
}
#Return result
return(term_test)
}
searchParse("Income Supplemental Quarterly Census of ")
searchParse("Incom Supplemental Quarterly Census of ")
searchParse("Income Supplemental Quarterly Census of ")
searchParse("Incom Supplemental Quarterly Census of ")
searchParse("Incom Supplemental Quarterly Census of ", spellCheck=FALSE)
searchParse("Incom Supplemental Quarterly Census of ", spellCheck=TRUE)
#' Parses, spell checks, and prepares a search query for standardization
#' by creating n-grams
#' @param   Option to render results in an interactive DT
#' @param spellCheck  Is true to force spellcheck
#' @import hunspell
#' @export
searchParse <- function(rec, spellCheck = TRUE){
requireNamespace('hunspell', quietly = TRUE)
splits <-  unlist(strsplit(rec," "))
##Spell check using hunspell
if(spellCheck == TRUE){
for(k in 1:length(splits)){
if(length(unlist(hunspell_find(splits[k])))>0){
splits[k] <- unlist(hunspell_suggest(splits[k]))[1]
}
}
}
##2 to 4 n-grams
term_test <- c()
if(length(splits)== 1){
} else if(length(splits)==2){
term_test <- rec
} else if(length(splits)>2){
for(k in 3:length(splits)){
term_test <- c(term_test, paste(splits[k-2],splits[k-1], splits[k]))
if(k >3){
term_test <- c(term_test, paste(splits[k-3],splits[k-2],splits[k-1], splits[k]))
}
}
}
#Return result
return(term_test)
}
searchParse("Incom Supplemental Quarterly Census of ", spellCheck=TRUE)
library(devtools);
library(httr);
httr::set_config( config( ssl_verifypeer = 0L ));
key = "28290CCB-B01B-4280-8C53-DF956DBD3A99"
devtools::install_github(
'CommerceDataService/project-eu-us/eu.us.opendata',
auth_user = 'SigmaMonstR',
auth_token = '7833c2d33fa898604214a046e8cae566397db600'
)
library(eu.us.opendata)
